{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "bidimensional_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pttc9ratep4z"
      },
      "source": [
        "#### Importiamo le librerie necessarie. Useremo ResNet50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4b2cnLkAep45"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image as kimage\n",
        "from tensorflow.keras.applications import resnet50, inception_v3\n",
        "import pandas as pd\n",
        "import datetime, os\n",
        "import shutil\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF-5OVwEW_-v",
        "outputId": "7f98531d-7820-49e9-8d57-8f00449aa955"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5DQMhboW5eb"
      },
      "source": [
        "import zipfile, os\n",
        "# this would take very long !!!\n",
        "base_dir = '/content/drive/MyDrive/DSIM_project/images_animals10_split.zip'\n",
        "zip = zipfile.ZipFile(f'{base_dir}')\n",
        "zip.extractall()\n",
        "zip.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN_Kv56mep46"
      },
      "source": [
        "## Creiamo train e test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ygvdIc_Cep46"
      },
      "source": [
        "dest_train = \"images_animals10_split/train/\"\n",
        "dest_test = \"images_animals10_split/test/\"\n",
        "dest_val = \"images_animals10_split/val/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8WUzQd0ep47"
      },
      "source": [
        "## Prima configurazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGpRXoDAjm_X"
      },
      "source": [
        "#### Creiamo i generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu2ZOKWZep47"
      },
      "source": [
        "train_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= resnet50.preprocess_input,\n",
        "                                                                shear_range=0.2,\n",
        "                                                                zoom_range=0.2,\n",
        "                                                                horizontal_flip=True,\n",
        "                                                                rotation_range=20,\n",
        "                                                                width_shift_range=0.2,\n",
        "                                                                height_shift_range=0.2,\n",
        "                                                                brightness_range=[0.5, 1.5])\n",
        "\n",
        "\n",
        "train_generator = train_processing.flow_from_directory(directory = dest_train,\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = True,\n",
        "                                    seed = 1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLuQBNRwep48"
      },
      "source": [
        "val_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
        "\n",
        "val_generator = val_processing.flow_from_directory(\n",
        "        directory=dest_val,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G1v1cSKFep48"
      },
      "source": [
        "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
        "\n",
        "test_generator = test_processing.flow_from_directory(\n",
        "        directory=dest_test,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liCCf_ayep48"
      },
      "source": [
        "#### Importiamo il modello con i pesi adatti (imagenet), e settiamo i layer iniziali come non allenabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKooKyrnep49"
      },
      "source": [
        "base_net = resnet50.ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_shape=(224, 224, 3), pooling=\"avg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0VD_S06ep49"
      },
      "source": [
        "for layer in base_net.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez5N5dn7ep49"
      },
      "source": [
        "#### Ora aggiungiamo due fully connected layers e poi creiamo un nuovo modello \"net\", dato dalla combinazione dei due "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gto6yyLFep49"
      },
      "source": [
        "# Output of the base_net model\n",
        "x = base_net.output\n",
        "# intermediate fully-connected layer + ReLU\n",
        "x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "# final fully-connected layer + SoftMax \n",
        "pred = keras.layers.Dense(n_species, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyBhTyFjep49"
      },
      "source": [
        "net1 = keras.Model(inputs=base_net.input, outputs=pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSYus4Vkep4-"
      },
      "source": [
        "net1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjXYG-23ep4-"
      },
      "source": [
        "#### Compiliamo il modello usando come loss la categorical crossentropy, come optimizer RMSprop e come metrica l'accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE5iyl6Lep4-"
      },
      "source": [
        "net1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer=keras.optimizers.RMSprop(),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQWUnG7wep4-"
      },
      "source": [
        "#### Ora fittiamo il modello con 10 epoche e visualizziamo i risultati in termini di accuracy e loss su train e test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz7T26e4ep4_"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"bidim_weights\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor=\"val_acc\",\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O1509bumep4_"
      },
      "source": [
        "history1 = net1.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[tensorboard_callback, cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu9RHpItep4_"
      },
      "source": [
        "#Open tensorboard\n",
        "#Open localhost:6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDj4bL00ep4_"
      },
      "source": [
        "def accuracy_loss(history):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    #\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label = \"train_accuracy\", color = \"red\")\n",
        "    plt.plot(history.history['val_accuracy'], label=\"train_accuracy\", color =\"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Accuracy', size = 15)\n",
        "    #\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label = \"Train loss\", color = \"red\")\n",
        "    plt.plot(history.history['val_loss'], label=\"Test loss\", color = \"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Loss', size = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_eHWplGkJ2g"
      },
      "source": [
        "json_config = net1.to_json(\"bidim_model\")\r\n",
        "\r\n",
        "load_status = net1.load_weights(\"bidim_weights\")\r\n",
        "load_status.assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq8G7YvEep5A"
      },
      "source": [
        "performance1 = net1.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ae3z1hnbep5A"
      },
      "source": [
        "accuracy_loss(history1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}