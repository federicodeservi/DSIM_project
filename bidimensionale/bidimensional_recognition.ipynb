{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importiamo le librerie necessarie. Useremo ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from time import time\n",
    "from tensorflow.keras.applications import resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creiamo train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\JPEGImages\")\n",
    "species = [\"horse\", \"sheep\"]\n",
    "n_species= len(species)\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "new_filenames=[]\n",
    "for filename in filenames:\n",
    "    if any(substring in filename for substring in species) == True:\n",
    "        new_filenames.append(filename)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "num_samples = len(new_filenames)\n",
    "\n",
    "filesToFind = tf.random.shuffle(new_filenames)\n",
    "\n",
    "# Had an issue here but needed to define and then reference the filename variable itself for filename in os.listdir(folderPath):\n",
    "train_files = filesToFind[:int(num_samples*0.8)]\n",
    "val_files = filesToFind[int(num_samples*0.8): int(num_samples*0.9)]\n",
    "test_files = filesToFind[-int(num_samples*0.1):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dest_train = pathlib.Path(r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\train\\\\\")\n",
    "dest_val = pathlib.Path(r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\val\\\\\")\n",
    "dest_test = pathlib.Path(r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\test\\\\\")\n",
    "\n",
    "if os.path.isdir(dest_train):\n",
    "    print(\"Exists\")\n",
    "else:\n",
    "    print(\"Doesn't exists\")\n",
    "    os.mkdir(dest_train)\n",
    "if os.path.isdir(dest_val):\n",
    "    print(\"Exists\")\n",
    "else:\n",
    "    print(\"Doesn't exists\")\n",
    "    os.mkdir(dest_val)\n",
    "if os.path.isdir(dest_test):\n",
    "    print(\"Exists\")\n",
    "else:\n",
    "    print(\"Doesn't exists\")\n",
    "    os.mkdir(dest_test)\n",
    "\n",
    "for filename in train_files: \n",
    "    mystr = filename.numpy().decode(\"UTF-8\")\n",
    "    dest = str(dest_train)+\"\\\\\"+mystr[mystr.rfind(\"\\\\\")+1 : mystr.rfind(\"_\")]\n",
    "    print(dest)\n",
    "    if os.path.isdir(dest):\n",
    "        print(\"Exists\")\n",
    "    else:\n",
    "        print(\"Doesn't exists\")\n",
    "        os.mkdir(dest)\n",
    "    shutil.copy(mystr, dest)\n",
    "    \n",
    "for filename in val_files: \n",
    "    mystr = filename.numpy().decode(\"UTF-8\")\n",
    "    dest = str(dest_val)+\"\\\\\"+mystr[mystr.rfind(\"\\\\\")+1 : mystr.rfind(\"_\")]\n",
    "    if os.path.isdir(dest):\n",
    "        print(\"Exists\")\n",
    "    else:\n",
    "        print(\"Doesn't exists\")\n",
    "        os.mkdir(dest)\n",
    "    shutil.copy(mystr, dest)\n",
    "    \n",
    "for filename in test_files: \n",
    "    mystr = filename.numpy().decode(\"UTF-8\")\n",
    "    dest = str(dest_test)+\"\\\\\"+mystr[mystr.rfind(\"\\\\\")+1 : mystr.rfind(\"_\")]\n",
    "    if os.path.isdir(dest):\n",
    "        print(\"Exists\")\n",
    "    else:\n",
    "        print(\"Doesn't exists\")\n",
    "        os.mkdir(dest)\n",
    "    shutil.copy(mystr, dest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prima configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= resnet50.preprocess_input,\n",
    "                                                                shear_range=0.4,\n",
    "                                                                zoom_range=0.4,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                rotation_range=30,\n",
    "                                                                width_shift_range=0.3,\n",
    "                                                                height_shift_range=0.3,\n",
    "                                                                brightness_range=[0.5, 1.5])\n",
    "\n",
    "\n",
    "train_generator = train_processing.flow_from_directory(directory = r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\train\",\n",
    "                                    target_size = (224, 224),\n",
    "                                    color_mode = \"rgb\",\n",
    "                                    batch_size = 32,\n",
    "                                    class_mode = \"categorical\",\n",
    "                                    shuffle = True,\n",
    "                                    seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ora andiamo a definire il test generator, in cui non applicheremo alcun tipo di data agumentation ovviamente, in quanto i dati di test devono essere utilizzati come sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
    "\n",
    "val_generator = test_processing.flow_from_directory(\n",
    "        directory=r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\val\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
    "\n",
    "test_generator = test_processing.flow_from_directory(\n",
    "        directory=r\"C:\\Users\\feder\\Desktop\\AwA2-data\\Animals_with_Attributes2\\test\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importiamo il modello con i pesi adatti (imagenet), e settiamo i layer iniziali come non allenabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net = resnet50.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "\tinput_shape=(224, 224, 3), pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_net.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ora aggiungiamo due fully connected layers e poi creiamo un nuovo modello \"net\", dato dalla combinazione dei due "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the base_net model\n",
    "x = base_net.output\n",
    "# intermediate fully-connected layer + ReLU\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "# final fully-connected layer + SoftMax \n",
    "pred = keras.layers.Dense(n_species, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = keras.Model(inputs=base_net.input, outputs=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiliamo il modello usando come loss la categorical crossentropy, come optimizer RMSprop e come metrica l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.RMSprop(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ora fittiamo il modello con 10 epoche e visualizziamo i risultati in termini di accuracy e loss su train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = net1.fit(train_generator,\n",
    "          epochs=10,\n",
    "          validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss(history):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    #\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'], label = \"train_accuracy\", color = \"red\")\n",
    "    plt.plot(history.history['val_acc'], label=\"train_accuracy\", color =\"blue\")\n",
    "    plt.legend(loc='best', fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xlabel('Epochs', size = 15)\n",
    "    plt.ylabel('Accuracy', size = 15)\n",
    "    #\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label = \"Train loss\", color = \"red\")\n",
    "    plt.plot(history.history['val_loss'], label=\"Test loss\", color = \"blue\")\n",
    "    plt.legend(loc='best', fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xlabel('Epochs', size = 15)\n",
    "    plt.ylabel('Loss', size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance1 = net1.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy_loss(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
