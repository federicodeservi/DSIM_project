{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('dsim': conda)",
      "metadata": {
        "interpreter": {
          "hash": "c6d8b0923b4478c13753bcd1691855a9d3e14a2ebfbd74ecce2f10551e9ffca2"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "audio_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVTc15QOtdTl"
      },
      "source": [
        "#### Importiamo le librerie necessarie. Useremo ResNet50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qTHf-g4NtdTq"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from time import time\n",
        "from tensorflow.keras.applications import resnet50, vgg19, mobilenet_v2, xception\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime, os\n",
        "import pathlib\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "from IPython import display\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSyZgoNVtdTr"
      },
      "source": [
        "## Creiamo train e test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAYJalttdTr"
      },
      "source": [
        "## Prima configurazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7yMMFwtdTs"
      },
      "source": [
        "train_dir = \"data_mel/train\" \n",
        "val_dir = \"data_mel/val\"\n",
        "test_dir = \"data_mel/test\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQskAiVKtdTs"
      },
      "source": [
        "species = np.array(tf.io.gfile.listdir(str(train_dir)))\n",
        "species = species[species != 'README.md']\n",
        "n_classes= len(species)\n",
        "print('Species:', species)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Species: ['Alces_alces' 'Bos_taurus' 'Cervus_elaphus' 'Equus_caballus'\n 'Lutra_lutra' 'Ovis' 'Pan' 'Panthera_leo' 'Procyon' 'Vulpes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-MQZyotdTs"
      },
      "source": [
        "train_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= xception.preprocess_input)\n",
        "                                                                #shear_range=0.2,\n",
        "                                                                #zoom_range=0.2,\n",
        "                                                                #horizontal_flip=True,\n",
        "                                                                #rotation_range=20,\n",
        "                                                                #width_shift_range=0.2,\n",
        "                                                                #height_shift_range=0.2,\n",
        "                                                                #brightness_range=[0.5, 1.5])\n",
        "\n",
        "\n",
        "train_generator = train_processing.flow_from_directory(directory = train_dir,\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = True,\n",
        "                                    seed = 1234)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 916 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5kf-O-tdTt"
      },
      "source": [
        "#### Ora andiamo a definire il test generator, in cui non applicheremo alcun tipo di data agumentation ovviamente, in quanto i dati di test devono essere utilizzati come sono."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f99jQqbotdTt"
      },
      "source": [
        "val_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=xception.preprocess_input)\n",
        "\n",
        "val_generator = val_processing.flow_from_directory(\n",
        "        directory=val_dir,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 119 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xyrHmV2XtdTu"
      },
      "source": [
        "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=xception.preprocess_input)\n",
        "\n",
        "test_generator = test_processing.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK-GOsPmtdTu"
      },
      "source": [
        "#### Importiamo il modello con i pesi adatti (imagenet), e settiamo i layer iniziali come non allenabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuCoo-0qtdTu"
      },
      "source": [
        "base_net = xception.Xception(weights=\"imagenet\", include_top=False,\n",
        "\tinput_shape=(224, 224, 3), pooling=\"avg\")"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 18s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7u9YHWgtdTv"
      },
      "source": [
        "for layer in base_net.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_10 (InputLayer)           [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_10[0][0]                   \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_98 (Conv2D)              (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 55, 55, 128)  512         conv2d_98[0][0]                  \n__________________________________________________________________________________________________\nadd (Add)                       (None, 55, 55, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 55, 55, 128)  0           add[0][0]                        \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_99 (Conv2D)              (None, 28, 28, 256)  32768       add[0][0]                        \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 28, 28, 256)  1024        conv2d_99[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_100 (Conv2D)             (None, 14, 14, 728)  186368      add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 14, 14, 728)  2912        conv2d_100[0][0]                 \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n                                                                 batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_101 (Conv2D)             (None, 7, 7, 1024)   745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 7, 7, 1024)   4096        conv2d_101[0][0]                 \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nglobal_average_pooling2d_8 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 0\nNon-trainable params: 20,861,480\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_net.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siCEHa-YtdTv"
      },
      "source": [
        "#### Ora aggiungiamo due fully connected layers e poi creiamo un nuovo modello \"net\", dato dalla combinazione dei due "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjHBOkdotdTv"
      },
      "source": [
        "# Output of the base_net model\n",
        "x = base_net.output#get_layer('flatten').output\n",
        "# intermediate fully-connected layer + ReLU\n",
        "#x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "# final fully-connected layer + SoftMax \n",
        "pred = keras.layers.Dense(n_classes, activation='softmax')(x)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgZ91_C3tdTv"
      },
      "source": [
        "model1 = keras.Model(inputs=base_net.input, outputs=pred)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Conv2D(8, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.Conv2D(8, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(16, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.Conv2D(16, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Conv2D(32, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.Conv2D(32, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.Conv2D(64, kernel_size=(3,3), activation = 'relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Ud_lh1x6tdTw"
      },
      "source": [
        "#net1.summary()"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yczFxunUtdTw"
      },
      "source": [
        "#### Compiliamo il modello usando come loss la categorical crossentropy, come optimizer RMSprop e come metrica l'accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxdE0ubOtdTw"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer=keras.optimizers.Adam(lr=0.0005),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnD0eN0tdTw"
      },
      "source": [
        "#### Ora fittiamo il modello con 10 epoche e visualizziamo i risultati in termini di accuracy e loss su train e test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiXxh2StdTw"
      },
      "source": [
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath=\"monodim_weights\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_best_only=True,\n",
        "                                                 monitor=\"val_accuracy\",\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kTspceEitdTx"
      },
      "source": [
        "history1 = model.fit(train_generator,\n",
        "          epochs=50,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "29/29 [==============================] - 12s 275ms/step - loss: 2.3035 - accuracy: 0.1597 - val_loss: 2.0256 - val_accuracy: 0.2605\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.26050, saving model to monodim_weights\n",
            "Epoch 2/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 2.0290 - accuracy: 0.2835 - val_loss: 1.8555 - val_accuracy: 0.3950\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.26050 to 0.39496, saving model to monodim_weights\n",
            "Epoch 3/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 1.8138 - accuracy: 0.3844 - val_loss: 1.7377 - val_accuracy: 0.4370\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.39496 to 0.43697, saving model to monodim_weights\n",
            "Epoch 4/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.6660 - accuracy: 0.4508 - val_loss: 1.6430 - val_accuracy: 0.4790\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.43697 to 0.47899, saving model to monodim_weights\n",
            "Epoch 5/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.5154 - accuracy: 0.5147 - val_loss: 1.5723 - val_accuracy: 0.5042\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.47899 to 0.50420, saving model to monodim_weights\n",
            "Epoch 6/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.4104 - accuracy: 0.5509 - val_loss: 1.5193 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.50420 to 0.53782, saving model to monodim_weights\n",
            "Epoch 7/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 1.3495 - accuracy: 0.5836 - val_loss: 1.4710 - val_accuracy: 0.5042\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.53782\n",
            "Epoch 8/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.2959 - accuracy: 0.5989 - val_loss: 1.4374 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.53782\n",
            "Epoch 9/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.2090 - accuracy: 0.6329 - val_loss: 1.4094 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.53782\n",
            "Epoch 10/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.2148 - accuracy: 0.6293 - val_loss: 1.3767 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.53782\n",
            "Epoch 11/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.1376 - accuracy: 0.6666 - val_loss: 1.3566 - val_accuracy: 0.5042\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.53782\n",
            "Epoch 12/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 1.1105 - accuracy: 0.6861 - val_loss: 1.3346 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.53782\n",
            "Epoch 13/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 1.0813 - accuracy: 0.6712 - val_loss: 1.3187 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.53782\n",
            "Epoch 14/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 1.0289 - accuracy: 0.6936 - val_loss: 1.3015 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.53782\n",
            "Epoch 15/50\n",
            "29/29 [==============================] - 6s 198ms/step - loss: 1.0001 - accuracy: 0.7126 - val_loss: 1.2934 - val_accuracy: 0.5042\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.53782\n",
            "Epoch 16/50\n",
            "29/29 [==============================] - 6s 198ms/step - loss: 0.9520 - accuracy: 0.7232 - val_loss: 1.2814 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53782\n",
            "Epoch 17/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.9230 - accuracy: 0.7692 - val_loss: 1.2702 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.53782\n",
            "Epoch 18/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.9349 - accuracy: 0.7412 - val_loss: 1.2650 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53782\n",
            "Epoch 19/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.9129 - accuracy: 0.7378 - val_loss: 1.2540 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53782\n",
            "Epoch 20/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.8524 - accuracy: 0.7538 - val_loss: 1.2458 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.53782\n",
            "Epoch 21/50\n",
            "29/29 [==============================] - 6s 199ms/step - loss: 0.7779 - accuracy: 0.8101 - val_loss: 1.2374 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.53782\n",
            "Epoch 22/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.8407 - accuracy: 0.7837 - val_loss: 1.2330 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.53782\n",
            "Epoch 23/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.8136 - accuracy: 0.8018 - val_loss: 1.2242 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.53782\n",
            "Epoch 24/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.7789 - accuracy: 0.7821 - val_loss: 1.2280 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.53782\n",
            "Epoch 25/50\n",
            "29/29 [==============================] - 6s 203ms/step - loss: 0.8074 - accuracy: 0.7773 - val_loss: 1.2169 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.53782\n",
            "Epoch 26/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.7445 - accuracy: 0.7978 - val_loss: 1.2146 - val_accuracy: 0.5126\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.53782\n",
            "Epoch 27/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.7318 - accuracy: 0.8148 - val_loss: 1.2116 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.53782\n",
            "Epoch 28/50\n",
            "29/29 [==============================] - 6s 202ms/step - loss: 0.6723 - accuracy: 0.8386 - val_loss: 1.2053 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.53782\n",
            "Epoch 29/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.7005 - accuracy: 0.8205 - val_loss: 1.2003 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.53782\n",
            "Epoch 30/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.6755 - accuracy: 0.8271 - val_loss: 1.2118 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.53782\n",
            "Epoch 31/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.6808 - accuracy: 0.8185 - val_loss: 1.2044 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.53782\n",
            "Epoch 32/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.6607 - accuracy: 0.8483 - val_loss: 1.1977 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.53782\n",
            "Epoch 33/50\n",
            "29/29 [==============================] - 6s 202ms/step - loss: 0.6395 - accuracy: 0.8709 - val_loss: 1.2061 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.53782\n",
            "Epoch 34/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.6555 - accuracy: 0.8179 - val_loss: 1.1999 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.53782\n",
            "Epoch 35/50\n",
            "29/29 [==============================] - 6s 202ms/step - loss: 0.6627 - accuracy: 0.8265 - val_loss: 1.1982 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.53782\n",
            "Epoch 36/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.6176 - accuracy: 0.8624 - val_loss: 1.1990 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.53782 to 0.54622, saving model to monodim_weights\n",
            "Epoch 37/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.6264 - accuracy: 0.8390 - val_loss: 1.1889 - val_accuracy: 0.5546\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.54622 to 0.55462, saving model to monodim_weights\n",
            "Epoch 38/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.6306 - accuracy: 0.8610 - val_loss: 1.1994 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.55462\n",
            "Epoch 39/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5852 - accuracy: 0.8561 - val_loss: 1.1957 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.55462\n",
            "Epoch 40/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5743 - accuracy: 0.8490 - val_loss: 1.1904 - val_accuracy: 0.5546\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.55462\n",
            "Epoch 41/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5422 - accuracy: 0.8601 - val_loss: 1.1891 - val_accuracy: 0.5546\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.55462\n",
            "Epoch 42/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.5379 - accuracy: 0.8894 - val_loss: 1.1924 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.55462\n",
            "Epoch 43/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5471 - accuracy: 0.8789 - val_loss: 1.1826 - val_accuracy: 0.5630\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.55462 to 0.56303, saving model to monodim_weights\n",
            "Epoch 44/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5338 - accuracy: 0.8806 - val_loss: 1.1928 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.56303\n",
            "Epoch 45/50\n",
            "29/29 [==============================] - 6s 203ms/step - loss: 0.5530 - accuracy: 0.8866 - val_loss: 1.1830 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.56303\n",
            "Epoch 46/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5212 - accuracy: 0.8777 - val_loss: 1.1899 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.56303\n",
            "Epoch 47/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.5410 - accuracy: 0.8750 - val_loss: 1.1861 - val_accuracy: 0.5630\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.56303\n",
            "Epoch 48/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.5066 - accuracy: 0.8883 - val_loss: 1.1945 - val_accuracy: 0.5462\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.56303\n",
            "Epoch 49/50\n",
            "29/29 [==============================] - 6s 200ms/step - loss: 0.4867 - accuracy: 0.8806 - val_loss: 1.1898 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.56303\n",
            "Epoch 50/50\n",
            "29/29 [==============================] - 6s 201ms/step - loss: 0.4968 - accuracy: 0.9027 - val_loss: 1.1979 - val_accuracy: 0.5378\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.56303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB3L5rWntdTx"
      },
      "source": [
        "#Open tensorboard\n",
        "#Open localhost:6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm0Zw2xvtdTx"
      },
      "source": [
        "def accuracy_loss(history):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    #\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label = \"train_accuracy\", color = \"red\")\n",
        "    plt.plot(history.history['val_accuracy'], label=\"train_accuracy\", color =\"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Accuracy', size = 15)\n",
        "    #\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label = \"Train loss\", color = \"red\")\n",
        "    plt.plot(history.history['val_loss'], label=\"Test loss\", color = \"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Loss', size = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJuDkry8tzHS"
      },
      "source": [
        "monodim_model = net1.to_json()\n",
        "\n",
        "with open(\"monodim_model.json\", \"w\") as json_file:\n",
        "    json_file.write(monodim_model)\n",
        "    \n",
        "load_status = net1.load_weights(\"monodim_weights\")\n",
        "load_status.assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyyZ86j3tdTx"
      },
      "source": [
        "performance1 = net1.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0wvi3-ALtdTz"
      },
      "source": [
        "accuracy_loss(history1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}