{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "audio_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVTc15QOtdTl"
      },
      "source": [
        "#### Importiamo le librerie necessarie. Useremo ResNet50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qTHf-g4NtdTq"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from time import time\n",
        "from tensorflow.keras.applications import resnet50\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime, os\n",
        "import pathlib\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "from IPython import display\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSyZgoNVtdTr"
      },
      "source": [
        "## Creiamo train e test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAYJalttdTr"
      },
      "source": [
        "## Prima configurazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7yMMFwtdTs"
      },
      "source": [
        "train_dir = \"data_mel/train\" \n",
        "val_dir = \"data_mel/val\"\n",
        "test_dir = \"data_mel/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQskAiVKtdTs"
      },
      "source": [
        "species = np.array(tf.io.gfile.listdir(str(train_dir)))\n",
        "species = species[species != 'README.md']\n",
        "n_classes= len(species)\n",
        "print('Species:', species)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-MQZyotdTs"
      },
      "source": [
        "train_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= resnet50.preprocess_input)\n",
        "                                                                #shear_range=0.2,\n",
        "                                                                #zoom_range=0.2,\n",
        "                                                                #horizontal_flip=True,\n",
        "                                                                #rotation_range=20,\n",
        "                                                                #width_shift_range=0.2,\n",
        "                                                                #height_shift_range=0.2,\n",
        "                                                                #brightness_range=[0.5, 1.5])\n",
        "\n",
        "\n",
        "train_generator = train_processing.flow_from_directory(directory = train_dir,\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = True,\n",
        "                                    seed = 1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5kf-O-tdTt"
      },
      "source": [
        "#### Ora andiamo a definire il test generator, in cui non applicheremo alcun tipo di data agumentation ovviamente, in quanto i dati di test devono essere utilizzati come sono."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f99jQqbotdTt"
      },
      "source": [
        "val_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
        "\n",
        "val_generator = val_processing.flow_from_directory(\n",
        "        directory=val_dir,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xyrHmV2XtdTu"
      },
      "source": [
        "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
        "\n",
        "test_generator = test_processing.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK-GOsPmtdTu"
      },
      "source": [
        "#### Importiamo il modello con i pesi adatti (imagenet), e settiamo i layer iniziali come non allenabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuCoo-0qtdTu"
      },
      "source": [
        "base_net = resnet50.ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_shape=(224, 224, 3), pooling=\"avg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7u9YHWgtdTv"
      },
      "source": [
        "for layer in base_net.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siCEHa-YtdTv"
      },
      "source": [
        "#### Ora aggiungiamo due fully connected layers e poi creiamo un nuovo modello \"net\", dato dalla combinazione dei due "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjHBOkdotdTv"
      },
      "source": [
        "# Output of the base_net model\n",
        "x = base_net.output\n",
        "# intermediate fully-connected layer + ReLU\n",
        "x = keras.layers.Dense(512, activation='relu')(x)\n",
        "# final fully-connected layer + SoftMax \n",
        "pred = keras.layers.Dense(n_classes, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgZ91_C3tdTv"
      },
      "source": [
        "net1 = keras.Model(inputs=base_net.input, outputs=pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Ud_lh1x6tdTw"
      },
      "source": [
        "#net1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yczFxunUtdTw"
      },
      "source": [
        "#### Compiliamo il modello usando come loss la categorical crossentropy, come optimizer RMSprop e come metrica l'accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxdE0ubOtdTw"
      },
      "source": [
        "net1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer=keras.optimizers.Adam(),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnD0eN0tdTw"
      },
      "source": [
        "#### Ora fittiamo il modello con 10 epoche e visualizziamo i risultati in termini di accuracy e loss su train e test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiXxh2StdTw"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"monodim_weights\",\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor=\"val_acc\",\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kTspceEitdTx"
      },
      "source": [
        "history1 = net1.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB3L5rWntdTx"
      },
      "source": [
        "#Open tensorboard\n",
        "#Open localhost:6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm0Zw2xvtdTx"
      },
      "source": [
        "def accuracy_loss(history):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    #\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label = \"train_accuracy\", color = \"red\")\n",
        "    plt.plot(history.history['val_accuracy'], label=\"train_accuracy\", color =\"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Accuracy', size = 15)\n",
        "    #\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label = \"Train loss\", color = \"red\")\n",
        "    plt.plot(history.history['val_loss'], label=\"Test loss\", color = \"blue\")\n",
        "    plt.legend(loc='best', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Loss', size = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJuDkry8tzHS"
      },
      "source": [
        "json_config = net1.to_json(\"monodim_model\")\r\n",
        "\r\n",
        "load_status = net1.load_weights(\"monodim_weights\")\r\n",
        "load_status.assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyyZ86j3tdTx"
      },
      "source": [
        "performance1 = net1.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0wvi3-ALtdTz"
      },
      "source": [
        "accuracy_loss(history1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}